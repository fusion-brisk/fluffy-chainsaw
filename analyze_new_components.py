#!/usr/bin/env python3
"""
–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ù–û–í–´–• –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –∏–∑ iPhone 17 HTML.
–°–æ–∑–¥–∞—ë–º –º–∞–ø–ø–∏–Ω–≥ –¥–ª—è –ø–∞—Ä—Å–µ—Ä–∞.
"""

import re
from bs4 import BeautifulSoup
from pathlib import Path
from collections import Counter


def analyze_component(soup, component_name: str, max_examples: int = 3):
    """–î–µ—Ç–∞–ª—å–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç."""
    print(f"\n{'='*80}")
    print(f"üîç –ö–æ–º–ø–æ–Ω–µ–Ω—Ç: {component_name}")
    print('='*80)
    
    elements = soup.find_all(class_=re.compile(rf'^{component_name}(?:_|-|\s|$)'))
    print(f"–ù–∞–π–¥–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(elements)}")
    
    if not elements:
        return None
    
    # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    print(f"\nüìã –í–∞—Ä–∏–∞–Ω—Ç—ã –∫–ª–∞—Å—Å–æ–≤:")
    class_variants = Counter()
    for el in elements:
        for cls in el.get('class', []):
            if component_name in cls:
                class_variants[cls] += 1
    
    for cls, cnt in class_variants.most_common(15):
        print(f"    {cls}: {cnt}")
    
    # –ü—Ä–∏–º–µ—Ä—ã —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
    print(f"\nüìù –ü—Ä–∏–º–µ—Ä—ã —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ (–ø–µ—Ä–≤—ã–µ {max_examples}):")
    for idx, el in enumerate(elements[:max_examples]):
        print(f"\n  --- –ü—Ä–∏–º–µ—Ä #{idx+1} ---")
        classes = ' '.join(el.get('class', []))[:80]
        print(f"  –ö–ª–∞—Å—Å: {classes}")
        
        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        children_summary = []
        for child in el.find_all(recursive=False):
            child_cls = ' '.join(child.get('class', []))[:40] or child.name
            children_summary.append(child_cls)
        
        if children_summary:
            print(f"  –î–µ—Ç–∏ (–ø—Ä—è–º—ã–µ): {', '.join(children_summary[:5])}")
        
        # –¢–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        text = el.get_text(strip=True)[:100]
        if text:
            print(f"  –¢–µ–∫—Å—Ç: {text}...")
        
        # –ê—Ç—Ä–∏–±—É—Ç—ã
        attrs = {k: v[:50] if isinstance(v, str) else v for k, v in el.attrs.items() if k != 'class'}
        if attrs:
            print(f"  –ê—Ç—Ä–∏–±—É—Ç—ã: {attrs}")
    
    return elements


def analyze_reviews(soup):
    """–ê–Ω–∞–ª–∏–∑ EReviews."""
    print("\n" + "="*80)
    print("‚≠ê –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó: EReviews (–æ—Ç–∑—ã–≤—ã/—Ä–µ–π—Ç–∏–Ω–≥ –º–∞–≥–∞–∑–∏–Ω–∞)")
    print("="*80)
    
    reviews = soup.find_all(class_=re.compile(r'EReviews'))
    
    for idx, rev in enumerate(reviews[:5]):
        print(f"\n--- EReviews #{idx+1} ---")
        
        # –ò—â–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤–Ω—É—Ç—Ä–∏
        shop_text = rev.find(class_=re.compile(r'EReviews-ShopText'))
        if shop_text:
            text = shop_text.get_text(strip=True)
            print(f"  ShopText: {text}")
        
        # –ï—Å—Ç—å –ª–∏ thumbnail
        thumb = rev.find(class_=re.compile(r'withThumb'))
        if thumb:
            print(f"  –° –º–∏–Ω–∏–∞—Ç—é—Ä–æ–π: –¥–∞")
        
        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–ª–∞—Å—Å–æ–≤
        classes = ' '.join(rev.get('class', []))
        print(f"  –ö–ª–∞—Å—Å—ã: {classes[:80]}")


def analyze_quote(soup):
    """–ê–Ω–∞–ª–∏–∑ EQuote."""
    print("\n" + "="*80)
    print("üí¨ –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó: EQuote (—Ü–∏—Ç–∞—Ç—ã –∏–∑ –æ—Ç–∑—ã–≤–æ–≤)")
    print("="*80)
    
    quotes = soup.find_all(class_=re.compile(r'^EQuote(?:_|-|\s|$)'))
    
    for idx, q in enumerate(quotes[:5]):
        print(f"\n--- EQuote #{idx+1} ---")
        
        # –ê–≤–∞—Ç–∞—Ä
        avatar = q.find(class_=re.compile(r'EQuote-AuthorAvatar'))
        if avatar:
            img = avatar.find('img')
            if img:
                src = img.get('src', img.get('data-src', ''))[:60]
                print(f"  –ê–≤–∞—Ç–∞—Ä: {src}...")
        
        # –¢–µ–∫—Å—Ç —Ü–∏—Ç–∞—Ç—ã
        text_el = q.find(class_=re.compile(r'EQuote-Text'))
        if text_el:
            text = text_el.get_text(strip=True)[:100]
            print(f"  –¶–∏—Ç–∞—Ç–∞: {text}...")
        
        # –†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        parent = q.parent
        if parent:
            parent_cls = ' '.join(parent.get('class', []))[:60]
            print(f"  –†–æ–¥–∏—Ç–µ–ª—å: {parent_cls}")


def analyze_product_tabs(soup):
    """–ê–Ω–∞–ª–∏–∑ EProductTabs."""
    print("\n" + "="*80)
    print("üìë –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó: EProductTabs (–≤–∫–ª–∞–¥–∫–∏ —Ç–æ–≤–∞—Ä–∞)")
    print("="*80)
    
    tabs_containers = soup.find_all(class_=re.compile(r'^EProductTabs(?:_|\s|$)'))
    
    for idx, container in enumerate(tabs_containers[:3]):
        print(f"\n--- EProductTabs #{idx+1} ---")
        
        # –û—Ç–¥–µ–ª—å–Ω—ã–µ –≤–∫–ª–∞–¥–∫–∏
        tabs = container.find_all(class_=re.compile(r'EProductTabs-Tab'))
        print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∫–ª–∞–¥–æ–∫: {len(tabs)}")
        
        for tab_idx, tab in enumerate(tabs[:5]):
            tab_text = tab.get_text(strip=True)[:30]
            is_active = 'active' in ' '.join(tab.get('class', []))
            status = "‚úÖ active" if is_active else ""
            print(f"    Tab {tab_idx+1}: {tab_text} {status}")
        
        # –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–∞–Ω–µ–ª–µ–π
        panes = container.find_all(class_=re.compile(r'EProductTabs-Pane'))
        print(f"  –ü–∞–Ω–µ–ª–µ–π: {len(panes)}")


def analyze_product_specs(soup):
    """–ê–Ω–∞–ª–∏–∑ EProductSpecs."""
    print("\n" + "="*80)
    print("üìã –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó: EProductSpecs (—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Ç–æ–≤–∞—Ä–∞)")
    print("="*80)
    
    specs_containers = soup.find_all(class_=re.compile(r'^EProductSpecs(?:_|\s|$)'))
    
    for idx, container in enumerate(specs_containers[:3]):
        print(f"\n--- EProductSpecs #{idx+1} ---")
        
        # –û—Ç–¥–µ–ª—å–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞
        properties = container.find_all(class_=re.compile(r'EProductSpecs-Property'))
        print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–æ–π—Å—Ç–≤: {len(properties)}")
        
        for prop_idx, prop in enumerate(properties[:10]):
            name_el = prop.find(class_=re.compile(r'EProductSpecs-PropertyName'))
            value_el = prop.find(class_=re.compile(r'EProductSpecs-PropertyValue'))
            
            name = name_el.get_text(strip=True) if name_el else "?"
            value = value_el.get_text(strip=True) if value_el else "?"
            print(f"    {name}: {value}")


def analyze_entity_card(soup):
    """–ê–Ω–∞–ª–∏–∑ EntityCard."""
    print("\n" + "="*80)
    print("üÉè –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó: EntityCard (–∫–∞—Ä—Ç–æ—á–∫–∞ —Å—É—â–Ω–æ—Å—Ç–∏)")
    print("="*80)
    
    cards = soup.find_all(class_=re.compile(r'^EntityCard(?:_|-|\s|$)'))
    
    for idx, card in enumerate(cards[:3]):
        print(f"\n--- EntityCard #{idx+1} ---")
        
        classes = ' '.join(card.get('class', []))
        print(f"  –ö–ª–∞—Å—Å—ã: {classes[:100]}")
        
        # Items –≤–Ω—É—Ç—Ä–∏
        items = card.find_all(class_=re.compile(r'EntityCard-Item|EntityCardItem'))
        print(f"  Items: {len(items)}")
        
        for item_idx, item in enumerate(items[:5]):
            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img = item.find('img')
            if img:
                src = img.get('src', '')[:40]
                alt = img.get('alt', '')[:30]
                print(f"    Item {item_idx+1}: img={src}... alt='{alt}'")
            else:
                text = item.get_text(strip=True)[:40]
                print(f"    Item {item_idx+1}: {text}")


def analyze_shop_split_discount(soup):
    """–ê–Ω–∞–ª–∏–∑ EShopSplitDiscount."""
    print("\n" + "="*80)
    print("üí≥ –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó: EShopSplitDiscount (–°–ø–ª–∏—Ç —Å–æ —Å–∫–∏–¥–∫–æ–π)")
    print("="*80)
    
    elements = soup.find_all(class_=re.compile(r'EShopSplitDiscount'))
    
    for idx, el in enumerate(elements[:5]):
        print(f"\n--- EShopSplitDiscount #{idx+1} ---")
        
        classes = ' '.join(el.get('class', []))
        print(f"  –ö–ª–∞—Å—Å—ã: {classes}")
        
        # –¶–µ–Ω–∞
        price_el = el.find(class_=re.compile(r'EShopSplitDiscount-Price'))
        if price_el:
            print(f"  –¶–µ–Ω–∞: {price_el.get_text(strip=True)}")
        
        # –°–∫–∏–¥–∫–∞
        discount_el = el.find(class_=re.compile(r'EShopSplitDiscount-DiscountLabel'))
        if discount_el:
            print(f"  –°–∫–∏–¥–∫–∞: {discount_el.get_text(strip=True)}")
        
        # –ú–µ—Ç–æ–¥ –æ–ø–ª–∞—Ç—ã
        pay_el = el.find(class_=re.compile(r'EShopSplitDiscount-PayMethod'))
        if pay_el:
            print(f"  –ú–µ—Ç–æ–¥ –æ–ø–ª–∞—Ç—ã: {pay_el.get_text(strip=True)}")
        
        # –ò–Ω—Ñ–æ
        info_el = el.find(class_=re.compile(r'EShopSplitDiscount-Info'))
        if info_el:
            print(f"  –ò–Ω—Ñ–æ: {info_el.get_text(strip=True)}")


def create_mapping_suggestions(soup):
    """–°–æ–∑–¥–∞—ë—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –º–∞–ø–ø–∏–Ω–≥—É –¥–ª—è snippet-parser.ts"""
    print("\n" + "="*80)
    print("üìù –ü–†–ï–î–õ–û–ñ–ï–ù–ò–Ø –ü–û –ú–ê–ü–ü–ò–ù–ì–£ –î–õ–Ø snippet-parser.ts")
    print("="*80)
    
    mappings = []
    
    # EReviews
    reviews = soup.find_all(class_=re.compile(r'^EReviews(?:_|\s|$)'))
    if reviews:
        mappings.append({
            'field': '#EReviews_ShopText',
            'selectors': ['.EReviews-ShopText', '[class*="EReviews-ShopText"]'],
            'description': '–¢–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–æ–≤ –º–∞–≥–∞–∑–∏–Ω–∞ (—Ä–µ–π—Ç–∏–Ω–≥ + –æ—Ç–∑—ã–≤—ã)',
            'count': len(reviews)
        })
    
    # EQuote
    quotes = soup.find_all(class_=re.compile(r'^EQuote(?:_|\s|$)'))
    if quotes:
        mappings.append({
            'field': '#EQuote_Text',
            'selectors': ['.EQuote-Text', '[class*="EQuote-Text"]'],
            'description': '–¢–µ–∫—Å—Ç —Ü–∏—Ç–∞—Ç—ã –∏–∑ –æ—Ç–∑—ã–≤–∞',
            'count': len(quotes)
        })
        mappings.append({
            'field': '#EQuote_Avatar',
            'selectors': ['.EQuote-AuthorAvatar img', '[class*="EQuote-AuthorAvatar"] img'],
            'description': '–ê–≤–∞—Ç–∞—Ä –∞–≤—Ç–æ—Ä–∞ —Ü–∏—Ç–∞—Ç—ã',
            'count': len(quotes)
        })
    
    # EProductSpecs
    specs = soup.find_all(class_=re.compile(r'^EProductSpecs(?:_|\s|$)'))
    if specs:
        mappings.append({
            'field': '#EProductSpecs',
            'selectors': ['.EProductSpecs', '[class*="EProductSpecs"]'],
            'description': '–ë–ª–æ–∫ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Ç–æ–≤–∞—Ä–∞',
            'count': len(specs)
        })
    
    # EShopSplitDiscount
    split_disc = soup.find_all(class_=re.compile(r'EShopSplitDiscount'))
    if split_disc:
        mappings.append({
            'field': '#EShopSplitDiscount',
            'selectors': ['.EShopSplitDiscount', '[class*="EShopSplitDiscount"]'],
            'description': '–ë–ª–æ–∫ –°–ø–ª–∏—Ç —Å–æ —Å–∫–∏–¥–∫–æ–π',
            'count': len(split_disc)
        })
        mappings.append({
            'field': '#EShopSplitDiscount_Price',
            'selectors': ['.EShopSplitDiscount-Price', '[class*="EShopSplitDiscount-Price"]'],
            'description': '–¶–µ–Ω–∞ –≤ –°–ø–ª–∏—Ç —Å–æ —Å–∫–∏–¥–∫–æ–π',
            'count': len(split_disc)
        })
    
    # EntityCard
    entity_cards = soup.find_all(class_=re.compile(r'^EntityCard(?:_|\s|$)'))
    if entity_cards:
        mappings.append({
            'field': '#EntityCard',
            'selectors': ['.EntityCard', '[class*="EntityCard"]'],
            'description': '–ö–∞—Ä—Ç–æ—á–∫–∞ —Å—É—â–Ω–æ—Å—Ç–∏ (–ø–æ—Ö–æ–∂–∏–µ —Ç–æ–≤–∞—Ä—ã)',
            'count': len(entity_cards)
        })
    
    # –í—ã–≤–æ–¥–∏–º –º–∞–ø–ø–∏–Ω–≥–∏
    print("\n// –î–æ–±–∞–≤–∏—Ç—å –≤ parsing-rules.ts –∏–ª–∏ parsing-rules.json:")
    print("// (–∏–ª–∏ –≤ src/utils/snippet-parser.ts)")
    print()
    
    for m in mappings:
        print(f"// {m['description']} ({m['count']} –Ω–∞–π–¥–µ–Ω–æ)")
        print(f"'{m['field']}': {{")
        print(f"    domSelectors: {m['selectors']},")
        print(f"    description: '{m['description']}'")
        print(f"}},")
        print()
    
    return mappings


if __name__ == "__main__":
    html_path = "/Users/shchuchkin/Documents/GitHub/fluffy-chainsaw/examples/iphone17.html"
    
    print(f"üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: {html_path}")
    
    with open(html_path, 'r', encoding='utf-8') as f:
        html = f.read()
    
    print(f"üìè –†–∞–∑–º–µ—Ä HTML: {len(html):,} –±–∞–π—Ç")
    
    soup = BeautifulSoup(html, 'html.parser')
    
    # –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    analyze_reviews(soup)
    analyze_quote(soup)
    analyze_product_tabs(soup)
    analyze_product_specs(soup)
    analyze_entity_card(soup)
    analyze_shop_split_discount(soup)
    
    # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –º–∞–ø–ø–∏–Ω–≥—É
    create_mapping_suggestions(soup)

