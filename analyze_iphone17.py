#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ HTML-—Ñ–∞–π–ª–∞ iPhone 17 –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–æ–≤—ã—Ö —Ç–∏–ø–æ–≤ —Å–Ω–∏–ø–ø–µ—Ç–æ–≤.
–ò—â–µ–º –∫–ª–∞—Å—Å—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Ç–µ–∫—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä—Å–µ—Ä–∞.
"""

import re
from bs4 import BeautifulSoup
from pathlib import Path
from collections import Counter

# –ò–∑–≤–µ—Å—Ç–Ω—ã–µ —Ç–∏–ø—ã –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ —Å–Ω–∏–ø–ø–µ—Ç–æ–≤
KNOWN_CONTAINERS = [
    'EShopItem', 'ESnippet', 'EProductSnippet2', 
    'Organic', 'Organic_withOfferInfo',
    'AdvProductGalleryCard'  # –†–µ–∫–ª–∞–º–∞ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
]

# –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤–Ω—É—Ç—Ä–∏ —Å–Ω–∏–ø–ø–µ—Ç–æ–≤
KNOWN_COMPONENTS = [
    'EPriceGroup', 'EPrice', 'LabelDiscount', 'ELabelRating',
    'EShopName', 'OfficialShop', 'EDeliveryGroup', 'EPriceBarometer',
    'Fintech', 'EBnpl', 'EMarketCheckoutLabel', 'Sitelinks',
    'OrganicUgcReviews', 'CoveredPhone', 'PromoOffer'
]


def analyze_html(html_path: str):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç HTML –∏ –Ω–∞—Ö–æ–¥–∏—Ç –Ω–æ–≤—ã–µ —Ç–∏–ø—ã —Å–Ω–∏–ø–ø–µ—Ç–æ–≤ –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤."""
    
    print(f"üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: {html_path}")
    
    with open(html_path, 'r', encoding='utf-8') as f:
        html = f.read()
    
    print(f"üìè –†–∞–∑–º–µ—Ä HTML: {len(html):,} –±–∞–π—Ç ({len(html)/1024/1024:.2f} MB)")
    
    soup = BeautifulSoup(html, 'html.parser')
    
    # 1. –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã —Å –ø—Ä–µ—Ñ–∏–∫—Å–∞–º–∏ E* (–∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã Yandex)
    all_classes = Counter()
    for el in soup.find_all(class_=True):
        for cls in el.get('class', []):
            # –ò–Ω—Ç–µ—Ä–µ—Å—É—é—Ç –∫–ª–∞—Å—Å—ã, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å E (EShopItem, EPrice –∏ —Ç.–¥.)
            if cls.startswith('E') or 'Snippet' in cls or 'Product' in cls:
                all_classes[cls] += 1
    
    print("\n" + "="*80)
    print("üîç –ö–õ–ê–°–°–´-–ö–û–ú–ü–û–ù–ï–ù–¢–´ (E* –∏ *Snippet*)")
    print("="*80)
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–æ—Ä–Ω–µ–≤–æ–º—É –∏–º–µ–Ω–∏ (–¥–æ –ø–µ—Ä–≤–æ–≥–æ _ –∏–ª–∏ -)
    grouped = {}
    for cls, count in all_classes.most_common():
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤–æ–µ –∏–º—è
        base = cls.split('_')[0].split('-')[0]
        if base not in grouped:
            grouped[base] = []
        grouped[base].append((cls, count))
    
    for base, variants in sorted(grouped.items(), key=lambda x: -sum(v[1] for v in x[1])):
        total = sum(v[1] for v in variants)
        is_known = any(k in base for k in KNOWN_COMPONENTS + KNOWN_CONTAINERS)
        status = "‚úÖ" if is_known else "‚ùå NEW"
        
        print(f"\n{status} {base} (total: {total})")
        for cls, cnt in sorted(variants, key=lambda x: -x[1])[:10]:
            print(f"    - {cls}: {cnt}")
    
    # 2. –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã —Å–Ω–∏–ø–ø–µ—Ç–æ–≤
    print("\n" + "="*80)
    print("üì¶ –ö–û–ù–¢–ï–ô–ù–ï–†–´ –°–ù–ò–ü–ü–ï–¢–û–í")
    print("="*80)
    
    containers = []
    for container_name in KNOWN_CONTAINERS:
        found = soup.find_all(class_=re.compile(rf'^{container_name}(?:_|\s|$)'))
        if found:
            containers.extend(found)
            print(f"  ‚úÖ {container_name}: {len(found)}")
        else:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
            found_partial = soup.find_all(class_=re.compile(rf'{container_name}'))
            if found_partial:
                containers.extend(found_partial)
                print(f"  ‚ö†Ô∏è {container_name} (partial): {len(found_partial)}")
    
    # 3. –ò—â–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –Ω–æ–≤—ã–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã —Å–Ω–∏–ø–ø–µ—Ç–æ–≤
    print("\n" + "="*80)
    print("üîé –ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–û –ù–û–í–´–ï –ö–û–ù–¢–ï–ô–ù–ï–†–´")
    print("="*80)
    
    # –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–º–∏ –¥–ª—è —Å–Ω–∏–ø–ø–µ—Ç–æ–≤
    potential_new = []
    
    # –ò—â–µ–º –ø–æ data-–∞—Ç—Ä–∏–±—É—Ç–∞–º
    for el in soup.find_all(attrs={'data-cid': True}):
        classes = ' '.join(el.get('class', []))
        if not any(k in classes for k in KNOWN_CONTAINERS):
            potential_new.append((classes[:80], el.name))
    
    # –ò—â–µ–º –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ (—ç–ª–µ–º–µ–Ω—Ç—ã —Å —Ü–µ–Ω–æ–π –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º)
    for el in soup.find_all(class_=re.compile(r'Price|Image|Title')):
        parent = el.parent
        if parent:
            parent_classes = ' '.join(parent.get('class', []))
            if not any(k in parent_classes for k in KNOWN_CONTAINERS) and 'Adv' not in parent_classes:
                if parent_classes and len(parent_classes) < 100:
                    potential_new.append((parent_classes, parent.name))
    
    # –í—ã–≤–æ–¥–∏–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ
    unique_new = set(potential_new)
    for classes, tag in sorted(unique_new)[:30]:
        print(f"  ‚ùì <{tag}> class='{classes}'")
    
    # 4. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å–Ω–∏–ø–ø–µ—Ç—ã –¥–ª—è –º–∞–ø–ø–∏–Ω–≥–∞
    print("\n" + "="*80)
    print("üìä –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –°–ù–ò–ü–ü–ï–¢–û–í (–ø–µ—Ä–≤—ã–µ 5)")
    print("="*80)
    
    for idx, container in enumerate(containers[:5]):
        print(f"\n--- –°–Ω–∏–ø–ø–µ—Ç #{idx+1} ---")
        container_class = ' '.join(container.get('class', []))[:60]
        print(f"–ö–ª–∞—Å—Å: {container_class}...")
        
        # –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
        title_el = container.find(class_=re.compile(r'Title'))
        if title_el:
            print(f"  üìù Title: {title_el.get_text(strip=True)[:50]}...")
        
        # –¶–µ–Ω–∞
        price_el = container.find(class_=re.compile(r'Price.*Value|Price$'))
        if price_el:
            print(f"  üí∞ Price: {price_el.get_text(strip=True)}")
        
        # –ú–∞–≥–∞–∑–∏–Ω
        shop_el = container.find(class_=re.compile(r'ShopName|Shop'))
        if shop_el:
            print(f"  üè™ Shop: {shop_el.get_text(strip=True)[:30]}...")
        
        # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img_el = container.find('img')
        if img_el:
            src = img_el.get('src', img_el.get('data-src', ''))[:60]
            print(f"  üñºÔ∏è Image: {src}...")
        
        # –í–ª–æ–∂–µ–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        components = []
        for comp in KNOWN_COMPONENTS:
            found = container.find(class_=re.compile(rf'{comp}'))
            if found:
                components.append(comp)
        if components:
            print(f"  üß© Components: {', '.join(components)}")
        
        # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (E*)
        unknown = []
        for el in container.find_all(class_=True):
            for cls in el.get('class', []):
                if cls.startswith('E') and not any(k in cls for k in KNOWN_COMPONENTS + KNOWN_CONTAINERS):
                    base = cls.split('_')[0].split('-')[0]
                    if base not in unknown:
                        unknown.append(base)
        if unknown:
            print(f"  ‚ùì Unknown E-components: {', '.join(unknown[:10])}")

    # 5. –ò—â–µ–º —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–æ–≤—ã–µ —Ç–∏–ø—ã —Å–Ω–∏–ø–ø–µ—Ç–æ–≤
    print("\n" + "="*80)
    print("üÜï –ü–û–ò–°–ö –ù–û–í–´–• –¢–ò–ü–û–í –°–ù–ò–ü–ü–ï–¢–û–í")
    print("="*80)
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–ª–∞—Å—Å–æ–≤ –≤–∏–¥–∞ "XXXSnippet" –∏–ª–∏ "EXxx" –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º–∏
    snippet_pattern = re.compile(r'\b(E[A-Z][a-zA-Z0-9]+|[A-Z][a-zA-Z]+Snippet[0-9]*)\b')
    
    potential_snippets = Counter()
    for el in soup.find_all(class_=True):
        for cls in el.get('class', []):
            matches = snippet_pattern.findall(cls)
            for m in matches:
                # –§–∏–ª—å—Ç—Ä—É–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ
                if not any(k in m for k in KNOWN_CONTAINERS + KNOWN_COMPONENTS):
                    potential_snippets[m] += 1
    
    print("\n–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –Ω–æ–≤—ã–µ —Ç–∏–ø—ã (—Ç–æ–ø-30):")
    for cls, cnt in potential_snippets.most_common(30):
        print(f"  ‚ùì {cls}: {cnt}")


if __name__ == "__main__":
    html_path = "/Users/shchuchkin/Documents/GitHub/fluffy-chainsaw/examples/iphone17.html"
    
    if not Path(html_path).exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {html_path}")
        exit(1)
    
    analyze_html(html_path)

